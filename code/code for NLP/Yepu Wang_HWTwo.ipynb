{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yepu Wang_HWTwo.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"aBHHUSP2XhGH"},"source":["import random\n","\n","def get_ngrams(n, text):\n","    words = text.split()\n","    \n","    for i in range(len(words)-(n - 1)):\n","        word = words[i + n-1]\n","        context = tuple(words[i:i + n-1])\n","        yield (word, context)\n","    return\n","\n","\n","class  NgramModel():\n","    def __init__(self, n):\n","        self.n = n\n","        self.ngram_counts = dict()\n","        self.context_counts = dict()\n","        self.vocabulary =[]\n","        \n","       \n","    def update(self, text):\n","        # this function will update the class/model internal counters\n","        self.text=text\n","        res = get_ngrams(self.n, text)\n","        no_words = len(text.split())\n","        # below 'n' is the number of SGML tags\n","        for _ in range(no_words):\n","            try:\n","                gen = next(res)\n","                word = gen[0]\n","                context = gen[1]\n","                if word not in self.vocabulary:\n","                    self.vocabulary.append(word)\n","                if (word,context) not in self.ngram_counts:\n","                    self.ngram_counts[(word, context)] = 1\n","                else:\n","                    self.ngram_counts[(word, context)] += 1\n","                if context not in self.context_counts:\n","                    self.context_counts[context] = 1\n","                else:\n","                    self.context_counts[context] += 1\n","            except StopIteration:\n","                break\n","        \n","    def get_vocab(self):\n","        return self.vocabulary\n","        \n","    def size_vocab(self):\n","        self.size_vocab=len(self.vocabulary)\n","    def prob(self, context, word):\n","        ngram = (word, context)\n","        if ngram not in self.context_counts and word in self.vocabulary:\n","            prob = 1 / len(self.vocabulary)\n","            return prob\n","        if word not in self.vocabulary:\n","            prob = 1 / (1+len(self.vocabulary))\n","            return prob\n","        else:\n","          prob = (self.ngram_counts[ngram] / self.context_counts[ngram[1]])\n","          return prob\n","\n","    def len_text(self):\n","        self.len_text= len(self.text)\n","    \n","    def len_ngram(self):\n","        self.len_ngram=len(self.ngram_counts)\n","    def word_freq(self, word):\n","        if word not in self.vocabulary:\n","            self.word_freq=1/(1+self.size_vocab)\n","        else:\n","            self.word_freq=self.vocabulary[word]\n","    def ngram_freq(self, gram):\n","        if gram not in self.ngram_counts:\n","            self.ngram_freq=1/(1+self.size_vocab)\n","        else:  \n","            self.ngram_freq=self.ngram_counts[gram]\n","    def generate_text (self, context, minlength,maxlength):\n","        length=random.randint(minlength,maxlength)\n","        y=[]\n","        for i in context:\n","            y.append(i)\n","        if len(context)<self.n-1:\n","            gram=random.sample(list(self.ngram_counts.keys()), 1) \n","            context=gram[0][1]\n","        else:\n","            context=context[-(self.n-1):]\n","       \n","        for i in range(length-(self.n-1)):\n","            m={}\n","            list1=[]\n","            for word in self.vocabulary:\n","                prob=self.prob(context,word)\n","                m[word]=prob\n","                \n","            for key,value in m.items():\n","                if(value == max(m.values())):\n","                    list1.append(key)\n","            gen_word=random.choice(list1)\n","            y.append(gen_word)\n","            a=(gen_word,)\n","            context=context+a\n","            context=context[-(self.n-1):]\n","        print(' '.join(y))\n","    def perplexity(self, test_text):\n","        res = get_ngrams(self.n, test_text)\n","        no_words = len(test_text.split())\n","        p=1\n","        for _ in range(no_words):\n","            try:\n","                gen = next(res)\n","                word = gen[0]\n","                context = gen[1]\n","                p=p*self.prob(context,word)\n","            except StopIteration:\n","                break\n","        length=no_words\n","        a=-(1/length)\n","        pp=p**(a)\n","        print (pp)\n","        \n","import requests\n","url = \"https://storm.cis.fordham.edu/~yli/data/MyShakespeare.txt\"\n","response=requests.get(url)\n","text=response.text\n","from string import punctuation\n","process_dicts={i:'' for i in punctuation}\n","#print(process_dicts)\n","punc_table = str.maketrans(process_dicts)\n","text= text.translate(punc_table)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aheduLtYJsQ","executionInfo":{"status":"ok","timestamp":1633134350359,"user_tz":-480,"elapsed":2455,"user":{"displayName":"Yepu Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16524686901209762124"}},"outputId":"16155193-f9ec-4f9a-89a7-5a1b5288b061"},"source":["a=NgramModel(3)\n","a.update(text)\n","#print(a.ngram_counts)\n","\n","context=('our', 'business')\n","word='I'\n","print(a.prob(context,word))\n","\n","context=('our','business')\n","minlength=maxlength=30\n","a.generate_text ( context, minlength,maxlength)\n","\n","test_text='make you a sword for me'\n","a.perplexity(test_text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0006153846153846154\n","our business particularise Your Tickled general conducted worse get fought agued quarterd advanced curse tremble remember much troth in disdain noon flayd Virgilia considering Tell Resolved Thither She wherein whereof\n","138.21937034197177\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjjZrA3TYaFc","executionInfo":{"status":"ok","timestamp":1633134352897,"user_tz":-480,"elapsed":2553,"user":{"displayName":"Yepu Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16524686901209762124"}},"outputId":"58b47ad2-f4f0-4eb2-abaa-39c9699fe520"},"source":["a=NgramModel(2)\n","a.update(text)\n","#print(a.ngram_counts)\n","\n","context=('our', 'business')\n","word='I'\n","print(a.prob(context,word))\n","\n","context=('our','business')\n","minlength=maxlength=30\n","a.generate_text ( context, minlength,maxlength)\n","\n","test_text='make you a sword for me'\n","a.perplexity(test_text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0006153846153846154\n","our business east countrymen serve impediment chain remain manchild dogs All Agrippa profess fit stand chain where valour prevaild any inventory Hecuba ladyship Till belly flour miles Opinion doom Thats Messenger\n","473.92665762299555\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXFiGdv1YcgG","executionInfo":{"status":"ok","timestamp":1633134355163,"user_tz":-480,"elapsed":2276,"user":{"displayName":"Yepu Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16524686901209762124"}},"outputId":"49c764d9-9ffb-400b-caca-62c465193ad7"},"source":["a=NgramModel(1)\n","a.update(text)\n","#print(a.ngram_counts)\n","\n","context=('our', 'business')\n","word='I'\n","print(a.prob(context,word))\n","\n","context=('our','business')\n","minlength=maxlength=30\n","a.generate_text ( context, minlength,maxlength)\n","\n","test_text='make you a sword for me'\n","a.perplexity(test_text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0006153846153846154\n","our business liking fill dined pricking noble and Brutus Those From forced Jupiter last hearts hearts Would name Your fine knee usury braggd oer they hither live covetous sword dozen spoons wonder\n","1624.9999999999993\n"]}]}]}