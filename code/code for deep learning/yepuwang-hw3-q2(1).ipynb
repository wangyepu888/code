{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This is funtional API\n\nimport numpy as np\nfrom tensorflow import keras\nfrom keras.preprocessing import image\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.optimizers import adam_v2\nAdam = adam_v2.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nfrom keras.callbacks import ModelCheckpoint \nfrom keras.utils.vis_utils import plot_model\n\n# Some Hyperparameters\nINPUT_DIM = (128,128,3) # Image dimension\nBATCH_SIZE = 512\nZ_DIM = 128 # Dimension of the latent vector (z)\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:09.952471Z","iopub.execute_input":"2021-11-14T05:37:09.952829Z","iopub.status.idle":"2021-11-14T05:37:09.960163Z","shell.execute_reply.started":"2021-11-14T05:37:09.952798Z","shell.execute_reply":"2021-11-14T05:37:09.959051Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"data_flow=image.ImageDataGenerator(rescale=1./255).flow_from_directory('../input/celebatrain', \n                                                                   target_size = INPUT_DIM[:2],\n                                                                   batch_size = BATCH_SIZE,\n                                                                   shuffle = True,\n                                                                   class_mode = 'input',\n                                                                   subset = 'training'\n                                                                   )","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:09.962145Z","iopub.execute_input":"2021-11-14T05:37:09.962956Z","iopub.status.idle":"2021-11-14T05:37:12.855233Z","shell.execute_reply.started":"2021-11-14T05:37:09.962917Z","shell.execute_reply":"2021-11-14T05:37:12.854404Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data_flow_test =image.ImageDataGenerator(rescale=1./255).flow_from_directory('../input/celebatest', \n                                                                   target_size = INPUT_DIM[:2],\n                                                                   batch_size = BATCH_SIZE,\n                                                                   shuffle = True,\n                                                                   class_mode = 'input',\n                                                                   subset = 'training'\n                                                                   )","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:12.856770Z","iopub.execute_input":"2021-11-14T05:37:12.857250Z","iopub.status.idle":"2021-11-14T05:37:13.078887Z","shell.execute_reply.started":"2021-11-14T05:37:12.857209Z","shell.execute_reply":"2021-11-14T05:37:13.078169Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from keras import initializations\nfrom tensorflow.keras import initializers\n\n\n# ENCODER\ndef build_vae_encoder(input_dim, output_dim, conv_filters, conv_kernel_size, \n                  conv_strides, use_batch_norm = False, use_dropout = False):\n  \n  # Clear tensorflow session to reset layer index numbers to 0 for LeakyRelu, \n  # BatchNormalization and Dropout.\n  # Otherwise, the names of above mentioned layers in the model \n  # would be inconsistent\n  global K\n  K.clear_session()\n  \n  # Number of Conv layers\n  n_layers = len(conv_filters)\n\n  # Define model input\n  encoder_input = Input(shape = input_dim, name = 'encoder_input',)\n  x = encoder_input\n\n  # Add convolutional layers\n  for i in range(n_layers):\n      x = Conv2D(filters = conv_filters[i], \n                  kernel_size = conv_kernel_size[i],\n                  strides = conv_strides[i], \n                  kernel_initializer=\"he_normal\",\n                  padding = 'same',\n                  name = 'encoder_conv_' + str(i)\n                  )(x)\n      if use_batch_norm:\n        x = BathcNormalization()(x)\n  \n      x = LeakyReLU()(x)\n\n      if use_dropout:\n        x = Dropout(rate=0.25)(x)\n\n  # Required for reshaping latent vector while building Decoder\n  shape_before_flattening = K.int_shape(x)[1:] \n  \n  x = Flatten()(x)\n  \n  mean_mu = Dense(output_dim, name = 'mu',kernel_initializer=\"he_normal\")(x)\n  log_var = Dense(output_dim, name = 'log_var',kernel_initializer=\"he_normal\")(x)\n\n  # Defining a function for sampling\n  def sampling(args):\n    mean_mu, log_var = args\n    epsilon = K.random_normal(shape=K.shape(mean_mu), mean=0., stddev=1.) \n    return mean_mu + K.exp(log_var/2)*epsilon   \n  \n  # Using a Keras Lambda Layer to include the sampling function as a layer \n  # in the model\n  encoder_output = Lambda(sampling, name='encoder_output')([mean_mu, log_var])\n\n  return encoder_input, encoder_output, mean_mu, log_var, shape_before_flattening, Model(encoder_input, encoder_output)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:13.080952Z","iopub.execute_input":"2021-11-14T05:37:13.081281Z","iopub.status.idle":"2021-11-14T05:37:13.091851Z","shell.execute_reply.started":"2021-11-14T05:37:13.081228Z","shell.execute_reply":"2021-11-14T05:37:13.090649Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"vae_encoder_input, vae_encoder_output,  mean_mu,log_var,  shape_before_flattening, vae_encoder  = build_vae_encoder(input_dim = INPUT_DIM,\n                                    output_dim = Z_DIM, \n                                    conv_filters = [32, 64, 64,64,64],\n                                    conv_kernel_size = [3,3,3,3,3],\n                                    conv_strides = [2,2,2,2,2])\n\nvae_encoder.summary()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:13.093145Z","iopub.execute_input":"2021-11-14T05:37:13.093906Z","iopub.status.idle":"2021-11-14T05:37:13.209166Z","shell.execute_reply.started":"2021-11-14T05:37:13.093865Z","shell.execute_reply":"2021-11-14T05:37:13.208529Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Decoder\ndef build_decoder(input_dim, shape_before_flattening, conv_filters, conv_kernel_size, \n                  conv_strides):\n\n  # Number of Conv layers\n  n_layers = len(conv_filters)\n\n  # Define model input\n  decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n\n  # To get an exact mirror image of the encoder\n  x = Dense(np.prod(shape_before_flattening))(decoder_input)\n  x = Reshape(shape_before_flattening)(x)\n\n  # Add convolutional layers\n  for i in range(n_layers):\n      x = Conv2DTranspose(filters = conv_filters[i], \n                  kernel_size = conv_kernel_size[i],\n                  kernel_initializer=\"he_normal\",\n                  strides = conv_strides[i], \n                  padding = 'same',\n                  name = 'decoder_conv_' + str(i)\n                  )(x)\n      \n      # Adding a sigmoid layer at the end to restrict the outputs \n      # between 0 and 1\n      if i < n_layers - 1:\n        x = LeakyReLU()(x)\n      else:\n        x = Activation('sigmoid')(x)\n\n  # Define model output\n  decoder_output = x\n\n  return decoder_input, decoder_output, Model(decoder_input, decoder_output)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:13.211054Z","iopub.execute_input":"2021-11-14T05:37:13.211310Z","iopub.status.idle":"2021-11-14T05:37:13.219133Z","shell.execute_reply.started":"2021-11-14T05:37:13.211278Z","shell.execute_reply":"2021-11-14T05:37:13.218414Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\ndecoder_input, decoder_output, vae_decoder = build_decoder(input_dim = Z_DIM,\n                                        shape_before_flattening = shape_before_flattening,\n                                        conv_filters = [64,64,64,32,3],\n                                        conv_kernel_size = [3,3,3,3,3],\n                                        conv_strides = [2,2,2,2,2]\n                                        )\nvae_decoder.summary()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:13.220424Z","iopub.execute_input":"2021-11-14T05:37:13.221288Z","iopub.status.idle":"2021-11-14T05:37:13.516733Z","shell.execute_reply.started":"2021-11-14T05:37:13.221226Z","shell.execute_reply":"2021-11-14T05:37:13.516005Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.framework.ops import disable_eager_execution\ndisable_eager_execution()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:13.517806Z","iopub.execute_input":"2021-11-14T05:37:13.518037Z","iopub.status.idle":"2021-11-14T05:37:13.523309Z","shell.execute_reply.started":"2021-11-14T05:37:13.518004Z","shell.execute_reply":"2021-11-14T05:37:13.522529Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"\n\n# The input to the model will be the image fed to the encoder.\nvae_input = vae_encoder_input\n\n# Output will be the output of the decoder. The term - decoder(encoder_output) \n# combines the model by passing the encoder output to the input of the decoder.\nvae_output = vae_decoder(vae_encoder_output)\n\n# Input to the combined model will be the input to the encoder.\n# Output of the combined model will be the output of the decoder.\nvae_model = Model(vae_input, vae_output)\n\nvae_model.summary()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:37:18.725646Z","iopub.execute_input":"2021-11-14T05:37:18.726196Z","iopub.status.idle":"2021-11-14T05:37:18.793692Z","shell.execute_reply.started":"2021-11-14T05:37:18.726157Z","shell.execute_reply":"2021-11-14T05:37:18.792983Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 0.0005\nN_EPOCHS = 20\nLOSS_FACTOR = 10000\ndef kl_loss(y_true, y_pred):\n    kl_loss =  -0.5 * K.sum(1 + log_var - K.square(mean_mu) - K.exp(log_var), axis = 1)\n    return kl_loss\n\ndef r_loss(y_true, y_pred):\n    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n\ndef total_loss(y_true, y_pred):\n    return LOSS_FACTOR*r_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\n\ndef L1_loss(y_true,y_pre): \n    return K.sum(K.abs(y_true-y_pre))\n\ndef L2_loss(y_true,y_pre):\n    return K.sum(K.square(y_true-y_pre), axis = [1,2,3])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T05:39:38.366180Z","iopub.execute_input":"2021-11-14T05:39:38.366888Z","iopub.status.idle":"2021-11-14T05:39:38.374318Z","shell.execute_reply.started":"2021-11-14T05:39:38.366848Z","shell.execute_reply":"2021-11-14T05:39:38.373242Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import adam_v2\nadam_optimizer = adam_v2.Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\nvae_model.compile(optimizer=adam_optimizer, loss = L2_loss,metrics=[L2_loss])\n\n#checkpoint_vae = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'VAE/weights.h5'), save_weights_only = True, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T05:39:42.415307Z","iopub.execute_input":"2021-11-14T05:39:42.415858Z","iopub.status.idle":"2021-11-14T05:39:42.455832Z","shell.execute_reply.started":"2021-11-14T05:39:42.415823Z","shell.execute_reply":"2021-11-14T05:39:42.455050Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES= 17902\nvae_model.fit_generator(data_flow,\n                        shuffle=True, \n                        epochs = N_EPOCHS,\n                        initial_epoch = 0, \n                        steps_per_epoch=NUM_IMAGES / BATCH_SIZE\n                       \n                      )","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:39:44.206317Z","iopub.execute_input":"2021-11-14T05:39:44.206864Z","iopub.status.idle":"2021-11-14T05:40:10.673769Z","shell.execute_reply.started":"2021-11-14T05:39:44.206830Z","shell.execute_reply":"2021-11-14T05:40:10.672094Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"markdown","source":"RECONSTRUCTION.","metadata":{"editable":false}},{"cell_type":"code","source":"\nexample_batch = next(data_flow_test)\nexample_batch = example_batch[0]\nexample_images = example_batch[:10]\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:34:51.125012Z","iopub.status.idle":"2021-11-14T05:34:51.129609Z","shell.execute_reply.started":"2021-11-14T05:34:51.129371Z","shell.execute_reply":"2021-11-14T05:34:51.129397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_compare_vae(images=None):\n  \n  if images is None:\n    example_batch = next(data_flow_test)\n    example_batch = example_batch[0]\n    images = example_batch[:10]\n\n  n_to_show = images.shape[0]\n  reconst_images = vae_model.predict(images)\n\n  fig = plt.figure(figsize=(15, 3))\n  fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n  for i in range(n_to_show):\n      img = images[i].squeeze()\n      sub = fig.add_subplot(2, n_to_show, i+1)\n      sub.axis('off')        \n      sub.imshow(img)\n\n  for i in range(n_to_show):\n      img = reconst_images[i].squeeze()\n      sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n      sub.axis('off')\n      sub.imshow(img)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:34:51.137187Z","iopub.status.idle":"2021-11-14T05:34:51.137821Z","shell.execute_reply.started":"2021-11-14T05:34:51.137599Z","shell.execute_reply":"2021-11-14T05:34:51.137622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplot_compare_vae(images = example_images)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:34:51.138999Z","iopub.status.idle":"2021-11-14T05:34:51.139679Z","shell.execute_reply.started":"2021-11-14T05:34:51.139403Z","shell.execute_reply":"2021-11-14T05:34:51.139426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating new faces from random vectors sampled from a standard normal distribution.","metadata":{"editable":false}},{"cell_type":"code","source":"def vae_generate_images(n_to_show=10):\n  reconst_images = vae_decoder.predict(np.random.normal(0,1,size=(n_to_show,Z_DIM)))\n\n  fig = plt.figure(figsize=(15, 3))\n  fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n  for i in range(n_to_show):\n        img = reconst_images[i].squeeze()\n        sub = fig.add_subplot(2, n_to_show, i+1)\n        sub.axis('off')        \n        sub.imshow(img)\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:34:51.141037Z","iopub.status.idle":"2021-11-14T05:34:51.141662Z","shell.execute_reply.started":"2021-11-14T05:34:51.141441Z","shell.execute_reply":"2021-11-14T05:34:51.141465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae_generate_images(n_to_show=10)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:34:51.142818Z","iopub.status.idle":"2021-11-14T05:34:51.143445Z","shell.execute_reply.started":"2021-11-14T05:34:51.143201Z","shell.execute_reply":"2021-11-14T05:34:51.143225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import norm\nz_test = vae_encoder.predict(example_batch[:200])\n\nx = np.linspace(-3, 3, 300)\n\nfig = plt.figure(figsize=(20, 20))\nfig.subplots_adjust(hspace=0.6, wspace=0.4)\n\nfor i in range(50):\n    ax = fig.add_subplot(5, 10, i+1)\n    ax.hist(z_test[:,i], density=True, bins = 20)\n    ax.axis('off')\n    ax.text(0.5, -0.35, str(i), fontsize=10, ha='center', transform=ax.transAxes)\n    ax.plot(x,norm.pdf(x))\n\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-14T05:34:51.144605Z","iopub.status.idle":"2021-11-14T05:34:51.145204Z","shell.execute_reply.started":"2021-11-14T05:34:51.144984Z","shell.execute_reply":"2021-11-14T05:34:51.145007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}