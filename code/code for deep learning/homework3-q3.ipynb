{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-23T16:55:38.533885Z","iopub.execute_input":"2021-11-23T16:55:38.534626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:10.078698Z","iopub.execute_input":"2021-11-23T17:27:10.079371Z","iopub.status.idle":"2021-11-23T17:27:10.088987Z","shell.execute_reply.started":"2021-11-23T17:27:10.079328Z","shell.execute_reply":"2021-11-23T17:27:10.087322Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport numpy as np\nimport os\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:12.582318Z","iopub.execute_input":"2021-11-23T17:27:12.582592Z","iopub.status.idle":"2021-11-23T17:27:14.141627Z","shell.execute_reply.started":"2021-11-23T17:27:12.582560Z","shell.execute_reply":"2021-11-23T17:27:14.140773Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"(a) Design, implement and train your RNN with the following constraints:\n• Use one-hot encoding for the input characters\n• One hidden layer of size 512 and one dense layer\n• Sequence length = 10\n• Batch size = 512","metadata":{}},{"cell_type":"code","source":"# RNN with 10 sequence\nwith open('/kaggle/input/fordham-deep-learning-hw3/anna.txt/anna.txt', 'r') as file:\n    text= file.read()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:14.608461Z","iopub.execute_input":"2021-11-23T17:27:14.609135Z","iopub.status.idle":"2021-11-23T17:27:14.623757Z","shell.execute_reply.started":"2021-11-23T17:27:14.609096Z","shell.execute_reply":"2021-11-23T17:27:14.622979Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"vocab = set([c for c in text])\nnb_chars = len(vocab)\nchar2index = dict((c, i) for i, c in enumerate(vocab))\nindex2char = dict((i, c) for i, c in enumerate(vocab))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:17.540541Z","iopub.execute_input":"2021-11-23T17:27:17.540831Z","iopub.status.idle":"2021-11-23T17:27:17.613837Z","shell.execute_reply.started":"2021-11-23T17:27:17.540795Z","shell.execute_reply":"2021-11-23T17:27:17.613124Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:40:05.308527Z","iopub.execute_input":"2021-11-23T16:40:05.309493Z","iopub.status.idle":"2021-11-23T16:40:05.31827Z","shell.execute_reply.started":"2021-11-23T16:40:05.309441Z","shell.execute_reply":"2021-11-23T16:40:05.317329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEQLEN = 10\nSTEP = 1\ninput_chars = []\nlabel_chars = []\n\nfor i in range(0, len(text) - SEQLEN, STEP):\n    input_chars.append(text[i:i + SEQLEN])\n    label_chars.append(text[i + SEQLEN])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:22.486515Z","iopub.execute_input":"2021-11-23T17:27:22.487080Z","iopub.status.idle":"2021-11-23T17:27:23.509404Z","shell.execute_reply.started":"2021-11-23T17:27:22.487037Z","shell.execute_reply":"2021-11-23T17:27:23.508602Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"Vectorizing input and label text...\")\nX = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\ny = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\nfor i, input_char in enumerate(input_chars):\n    for j, ch in enumerate(input_char):\n        X[i, j, char2index[ch]] = 1\n    y[i, char2index[label_chars[i]]] = 1","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:26.464609Z","iopub.execute_input":"2021-11-23T17:27:26.465256Z","iopub.status.idle":"2021-11-23T17:27:36.430560Z","shell.execute_reply.started":"2021-11-23T17:27:26.465212Z","shell.execute_reply":"2021-11-23T17:27:36.429772Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from keras.layers.recurrent import SimpleRNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:36.432229Z","iopub.execute_input":"2021-11-23T17:27:36.432520Z","iopub.status.idle":"2021-11-23T17:27:36.437607Z","shell.execute_reply.started":"2021-11-23T17:27:36.432465Z","shell.execute_reply":"2021-11-23T17:27:36.436513Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"HIDDEN_SIZE = 512\nBATCH_SIZE = 512\nNUM_ITERATIONS = 1\nNUM_EPOCHS_PER_ITERATION = 1\nNUM_PREDS_PER_EPOCH = 500","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:36.439939Z","iopub.execute_input":"2021-11-23T17:27:36.440469Z","iopub.status.idle":"2021-11-23T17:27:36.450525Z","shell.execute_reply.started":"2021-11-23T17:27:36.440428Z","shell.execute_reply":"2021-11-23T17:27:36.449778Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n\nmodel = Sequential()\nmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n                    input_shape=(100, nb_chars),\n                    unroll=True))\n\nmodel.add(Dense(nb_chars))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:01:22.500577Z","iopub.execute_input":"2021-11-23T17:01:22.501331Z","iopub.status.idle":"2021-11-23T17:01:23.000776Z","shell.execute_reply.started":"2021-11-23T17:01:22.50129Z","shell.execute_reply":"2021-11-23T17:01:22.999939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:02:04.775642Z","iopub.execute_input":"2021-11-23T17:02:04.775941Z","iopub.status.idle":"2021-11-23T17:02:05.243907Z","shell.execute_reply.started":"2021-11-23T17:02:04.775909Z","shell.execute_reply":"2021-11-23T17:02:05.243011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nstart = time.time()\n\n\n\n\nfor iteration in range(NUM_ITERATIONS):\n    print(\"=\" * 50)\n    print(\"Iteration #: %d\" % (iteration))\n    model.fit(X, y, batch_size=BATCH_SIZE, epochs=5)\n    \n    # testing model\n    # randomly choose a row from input_chars, then use it to \n    # generate text from model for next 100 chars\n    test_idx = np.random.randint(len(input_chars))\n    test_chars = input_chars[30]\n    print(\"Generating from seed: %s\" % (test_chars))\n    print(test_chars, end=\"\")\n    for i in range(NUM_PREDS_PER_EPOCH):\n        Xtest = np.zeros((1, SEQLEN, nb_chars))\n        for i, ch in enumerate(test_chars):\n            Xtest[0, i, char2index[ch]] = 1\n        pred = model.predict(Xtest, verbose=0)[0]\n        ypred = index2char[np.argmax(pred)]\n        print(ypred, end=\"\")\n        # move forward with test_chars + ypred\n        test_chars = test_chars[1:] + ypred\n    print()\n    stop = time.time()\n    print(f\"Training time: {stop - start}s\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:03:16.797247Z","iopub.execute_input":"2021-11-23T17:03:16.7979Z","iopub.status.idle":"2021-11-23T17:06:01.884402Z","shell.execute_reply.started":"2021-11-23T17:03:16.797831Z","shell.execute_reply":"2021-11-23T17:06:01.883556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile utils.py\nimport numpy as np\nfrom numpy import cov\nfrom numpy import trace\nfrom numpy import iscomplexobj\nfrom numpy import asarray\nfrom numpy.random import randint\nfrom scipy.linalg import sqrtm\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.datasets.mnist import load_data\nfrom tensorflow.keras.models import load_model\nfrom skimage.transform import resize\nimport math\nfrom pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel, OpenAIGPTLMHeadModel\nimport torch\n \n\ndef lmScore(sentence):\n\n\t'''\n\tinput sentence is string \n\tAnd output is the LM score by Bert\n\t'''\n\n\tgpt = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')\n\tgpt.eval()\n\t# Load pre-trained model tokenizer (vocabulary)\n\ttokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n\ttokenize_input = tokenizer.tokenize(sentence)\n\ttensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n\tloss = gpt(tensor_input, lm_labels=tensor_input)\n\treturn math.exp(loss)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:33:28.235552Z","iopub.execute_input":"2021-11-23T17:33:28.236215Z","iopub.status.idle":"2021-11-23T17:33:28.243138Z","shell.execute_reply.started":"2021-11-23T17:33:28.236170Z","shell.execute_reply":"2021-11-23T17:33:28.241938Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"t='all alike the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure the same time to be sure'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:50:57.383396Z","iopub.execute_input":"2021-11-23T16:50:57.383662Z","iopub.status.idle":"2021-11-23T16:50:57.387409Z","shell.execute_reply.started":"2021-11-23T16:50:57.383632Z","shell.execute_reply":"2021-11-23T16:50:57.386694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pytorch_pretrained_bert","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:50:58.952918Z","iopub.execute_input":"2021-11-23T16:50:58.95383Z","iopub.status.idle":"2021-11-23T16:51:07.750698Z","shell.execute_reply.started":"2021-11-23T16:50:58.953757Z","shell.execute_reply":"2021-11-23T16:51:07.749914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import lmScore\nlmScore(t)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:33:33.829069Z","iopub.execute_input":"2021-11-23T17:33:33.829357Z","iopub.status.idle":"2021-11-23T17:33:38.123601Z","shell.execute_reply.started":"2021-11-23T17:33:33.829326Z","shell.execute_reply":"2021-11-23T17:33:38.122786Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Rnn-100","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:51:19.589481Z","iopub.execute_input":"2021-11-23T16:51:19.589785Z","iopub.status.idle":"2021-11-23T16:51:19.59479Z","shell.execute_reply.started":"2021-11-23T16:51:19.589737Z","shell.execute_reply":"2021-11-23T16:51:19.593847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEQLEN = 100\nSTEP = 1\ninput_chars = []\nlabel_chars = []\n\nfor i in range(0, len(text) - SEQLEN, STEP):\n    input_chars.append(text[i:i + SEQLEN])\n    label_chars.append(text[i + SEQLEN])\nprint(\"Vectorizing input and label text...\")\nX = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\ny = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\nfor i, input_char in enumerate(input_chars):\n    for j, ch in enumerate(input_char):\n        X[i, j, char2index[ch]] = 1\n    y[i, char2index[label_chars[i]]] = 1","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:54:13.734679Z","iopub.execute_input":"2021-11-23T16:54:13.735278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RNN with 100 sequence\nSEQLEN = 100\nHIDDEN_SIZE = 512\nBATCH_SIZE = 512\nNUM_ITERATIONS = 1\nNUM_EPOCHS_PER_ITERATION = 1\nNUM_PREDS_PER_EPOCH = 500\n\nmodel = Sequential()\nmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n                    input_shape=(SEQLEN, nb_chars),\n                    unroll=True))\n\nmodel.add(Dense(nb_chars))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:38:58.931998Z","iopub.execute_input":"2021-11-23T16:38:58.932707Z","iopub.status.idle":"2021-11-23T16:38:59.147055Z","shell.execute_reply.started":"2021-11-23T16:38:58.932662Z","shell.execute_reply":"2021-11-23T16:38:59.145861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t='all alike the princess of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the conversation of the'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:07:11.704612Z","iopub.execute_input":"2021-11-23T17:07:11.705262Z","iopub.status.idle":"2021-11-23T17:07:11.709921Z","shell.execute_reply.started":"2021-11-23T17:07:11.705217Z","shell.execute_reply":"2021-11-23T17:07:11.709153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import lmScore\nlmScore(t)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:07:22.849405Z","iopub.execute_input":"2021-11-23T17:07:22.850168Z","iopub.status.idle":"2021-11-23T17:07:40.779212Z","shell.execute_reply.started":"2021-11-23T17:07:22.850126Z","shell.execute_reply":"2021-11-23T17:07:40.778456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LSTM-100\nfrom keras.layers import LSTM\nchars = set([c for c in text])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:46.973396Z","iopub.execute_input":"2021-11-23T17:27:46.974016Z","iopub.status.idle":"2021-11-23T17:27:47.038453Z","shell.execute_reply.started":"2021-11-23T17:27:46.973970Z","shell.execute_reply":"2021-11-23T17:27:47.037732Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(512, input_shape=(100, len(chars))))\n\nmodel.add(Dense(nb_chars))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:15:50.789002Z","iopub.execute_input":"2021-11-23T17:15:50.790014Z","iopub.status.idle":"2021-11-23T17:15:51.164365Z","shell.execute_reply.started":"2021-11-23T17:15:50.78996Z","shell.execute_reply":"2021-11-23T17:15:51.163574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:15:53.494855Z","iopub.execute_input":"2021-11-23T17:15:53.495158Z","iopub.status.idle":"2021-11-23T17:15:53.710588Z","shell.execute_reply.started":"2021-11-23T17:15:53.495127Z","shell.execute_reply":"2021-11-23T17:15:53.70977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nfor iteration in range(NUM_ITERATIONS):\n    print(\"=\" * 50)\n    print(\"Iteration #: %d\" % (iteration))\n    model.fit(X, y, batch_size=BATCH_SIZE, epochs=5)\n    \n    # testing model\n    # randomly choose a row from input_chars, then use it to \n    # generate text from model for next 100 chars\n    test_idx = np.random.randint(len(input_chars))\n    test_chars = input_chars[30]\n    print(\"Generating from seed: %s\" % (test_chars))\n    print(test_chars, end=\"\")\n    for i in range(NUM_PREDS_PER_EPOCH):\n        Xtest = np.zeros((1, SEQLEN, nb_chars))\n        for i, ch in enumerate(test_chars):\n            Xtest[0, i, char2index[ch]] = 1\n        pred = model.predict(Xtest, verbose=0)[0]\n        ypred = index2char[np.argmax(pred)]\n        print(ypred, end=\"\")\n        # move forward with test_chars + ypred\n        test_chars = test_chars[1:] + ypred\n    print()\n    stop = time.time()\n    print(f\"Training time: {stop - start}s\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:17:32.467998Z","iopub.execute_input":"2021-11-23T17:17:32.46856Z","iopub.status.idle":"2021-11-23T17:21:14.778817Z","shell.execute_reply.started":"2021-11-23T17:17:32.468521Z","shell.execute_reply":"2021-11-23T17:21:14.778073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t=' all alike, and the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the same time the'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:24:29.186827Z","iopub.execute_input":"2021-11-23T17:24:29.187574Z","iopub.status.idle":"2021-11-23T17:24:29.191546Z","shell.execute_reply.started":"2021-11-23T17:24:29.187532Z","shell.execute_reply":"2021-11-23T17:24:29.1908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import lmScore\nlmScore(t)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:24:45.565348Z","iopub.execute_input":"2021-11-23T17:24:45.566095Z","iopub.status.idle":"2021-11-23T17:24:49.324083Z","shell.execute_reply.started":"2021-11-23T17:24:45.566056Z","shell.execute_reply":"2021-11-23T17:24:49.323335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import GRU","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:27:57.118339Z","iopub.execute_input":"2021-11-23T17:27:57.118651Z","iopub.status.idle":"2021-11-23T17:27:57.123003Z","shell.execute_reply.started":"2021-11-23T17:27:57.118615Z","shell.execute_reply":"2021-11-23T17:27:57.122087Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(GRU(512, input_shape=(100, len(chars))))\n\nmodel.add(Dense(nb_chars))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:28:11.917586Z","iopub.execute_input":"2021-11-23T17:28:11.918371Z","iopub.status.idle":"2021-11-23T17:28:12.222963Z","shell.execute_reply.started":"2021-11-23T17:28:11.918321Z","shell.execute_reply":"2021-11-23T17:28:12.221917Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:28:16.076281Z","iopub.execute_input":"2021-11-23T17:28:16.076987Z","iopub.status.idle":"2021-11-23T17:28:16.300001Z","shell.execute_reply.started":"2021-11-23T17:28:16.076931Z","shell.execute_reply":"2021-11-23T17:28:16.298758Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nfor iteration in range(NUM_ITERATIONS):\n    print(\"=\" * 50)\n    print(\"Iteration #: %d\" % (iteration))\n    model.fit(X, y, batch_size=BATCH_SIZE, epochs=5)\n    \n    # testing model\n    # randomly choose a row from input_chars, then use it to \n    # generate text from model for next 100 chars\n    test_idx = np.random.randint(len(input_chars))\n    test_chars = input_chars[30]\n    print(\"Generating from seed: %s\" % (test_chars))\n    print(test_chars, end=\"\")\n    for i in range(NUM_PREDS_PER_EPOCH):\n        Xtest = np.zeros((1, SEQLEN, nb_chars))\n        for i, ch in enumerate(test_chars):\n            Xtest[0, i, char2index[ch]] = 1\n        pred = model.predict(Xtest, verbose=0)[0]\n        ypred = index2char[np.argmax(pred)]\n        print(ypred, end=\"\")\n        # move forward with test_chars + ypred\n        test_chars = test_chars[1:] + ypred\n    print()\n    stop = time.time()\n    print(f\"Training time: {stop - start}s\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:29:00.068982Z","iopub.execute_input":"2021-11-23T17:29:00.069751Z","iopub.status.idle":"2021-11-23T17:32:13.529377Z","shell.execute_reply.started":"2021-11-23T17:29:00.069687Z","shell.execute_reply":"2021-11-23T17:32:13.528560Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"t=' all alike, and was a stranger and still more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and more and m'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:33:02.733416Z","iopub.execute_input":"2021-11-23T17:33:02.734144Z","iopub.status.idle":"2021-11-23T17:33:02.738299Z","shell.execute_reply.started":"2021-11-23T17:33:02.734099Z","shell.execute_reply":"2021-11-23T17:33:02.737528Z"},"trusted":true},"execution_count":16,"outputs":[]}]}