{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/fordham-deep-learning-hw3/anna.txt/anna.txt', 'r') as file:\n    anna= file.read()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:36:48.999681Z","iopub.execute_input":"2021-11-20T14:36:49.000591Z","iopub.status.idle":"2021-11-20T14:36:49.099949Z","shell.execute_reply.started":"2021-11-20T14:36:49.000527Z","shell.execute_reply":"2021-11-20T14:36:49.099229Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport numpy as np\nimport os\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:36:52.638897Z","iopub.execute_input":"2021-11-20T14:36:52.639780Z","iopub.status.idle":"2021-11-20T14:36:59.351052Z","shell.execute_reply.started":"2021-11-20T14:36:52.639737Z","shell.execute_reply":"2021-11-20T14:36:59.349774Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text=anna","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:20.070229Z","iopub.execute_input":"2021-11-20T14:37:20.070628Z","iopub.status.idle":"2021-11-20T14:37:20.075964Z","shell.execute_reply.started":"2021-11-20T14:37:20.070587Z","shell.execute_reply":"2021-11-20T14:37:20.074919Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"chars = set([c for c in text])\nnb_chars = len(chars)\nchar2index = dict((c, i) for i, c in enumerate(chars))\nindex2char = dict((i, c) for i, c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:21.431463Z","iopub.execute_input":"2021-11-20T14:37:21.432584Z","iopub.status.idle":"2021-11-20T14:37:21.515719Z","shell.execute_reply.started":"2021-11-20T14:37:21.432506Z","shell.execute_reply":"2021-11-20T14:37:21.514777Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"vocab = sorted(set(anna))\nprint(f'{len(vocab)} unique characters')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:23.484644Z","iopub.execute_input":"2021-11-20T14:37:23.485479Z","iopub.status.idle":"2021-11-20T14:37:23.511719Z","shell.execute_reply.started":"2021-11-20T14:37:23.485422Z","shell.execute_reply":"2021-11-20T14:37:23.510379Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"anna[:100]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:26.020381Z","iopub.execute_input":"2021-11-20T14:37:26.021551Z","iopub.status.idle":"2021-11-20T14:37:26.032055Z","shell.execute_reply.started":"2021-11-20T14:37:26.021509Z","shell.execute_reply":"2021-11-20T14:37:26.030883Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"chars = tuple(set(anna))\nint2char = dict(enumerate(chars))\nchar2int = {ch: ii for ii, ch in int2char.items()}\nencoded = np.array([char2int[ch] for ch in anna])","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:28.301919Z","iopub.execute_input":"2021-11-20T14:37:28.302369Z","iopub.status.idle":"2021-11-20T14:37:28.871097Z","shell.execute_reply.started":"2021-11-20T14:37:28.302337Z","shell.execute_reply":"2021-11-20T14:37:28.870256Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# create inputs and labels from the text. We do this by stepping\n# through the text ${step} character at a time, and extracting a \n# sequence of size ${seqlen} and the next output char. For example,\n# assuming an input text \"The sky was falling\", we would get the \n# following sequence of input_chars and label_chars (first 5 only)\n#   The sky wa -> s\n#   he sky was ->  \n#   e sky was  -> f\n#    sky was f -> a\n#   sky was fa -> l\nprint(\"Creating input and label text...\")\nSEQLEN = 10\nSTEP = 1","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:32.703518Z","iopub.execute_input":"2021-11-20T14:37:32.703827Z","iopub.status.idle":"2021-11-20T14:37:32.709078Z","shell.execute_reply.started":"2021-11-20T14:37:32.703794Z","shell.execute_reply":"2021-11-20T14:37:32.708117Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_chars = []\nlabel_chars = []\nfor i in range(0, len(text) - SEQLEN, STEP):\n    input_chars.append(text[i:i + SEQLEN])\n    label_chars.append(text[i + SEQLEN])","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:35.841966Z","iopub.execute_input":"2021-11-20T14:37:35.842951Z","iopub.status.idle":"2021-11-20T14:37:37.080767Z","shell.execute_reply.started":"2021-11-20T14:37:35.842878Z","shell.execute_reply":"2021-11-20T14:37:37.079805Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"Vectorizing input and label text...\")\nX = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\ny = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\nfor i, input_char in enumerate(input_chars):\n    for j, ch in enumerate(input_char):\n        X[i, j, char2index[ch]] = 1\n    y[i, char2index[label_chars[i]]] = 1","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:39.377256Z","iopub.execute_input":"2021-11-20T14:37:39.378018Z","iopub.status.idle":"2021-11-20T14:37:51.529907Z","shell.execute_reply.started":"2021-11-20T14:37:39.377966Z","shell.execute_reply":"2021-11-20T14:37:51.529293Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.layers.recurrent import SimpleRNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:51.539110Z","iopub.execute_input":"2021-11-20T14:37:51.539378Z","iopub.status.idle":"2021-11-20T14:37:51.552784Z","shell.execute_reply.started":"2021-11-20T14:37:51.539348Z","shell.execute_reply":"2021-11-20T14:37:51.551934Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"HIDDEN_SIZE = 128\nBATCH_SIZE = 128\nNUM_ITERATIONS = 1\nNUM_EPOCHS_PER_ITERATION = 10\nNUM_PREDS_PER_EPOCH = 100\n\nmodel = Sequential()\nmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n                    input_shape=(SEQLEN, nb_chars),\n                    unroll=True))\nmodel.add(Dense(nb_chars))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:37:59.672161Z","iopub.execute_input":"2021-11-20T14:37:59.672581Z","iopub.status.idle":"2021-11-20T14:37:59.769579Z","shell.execute_reply.started":"2021-11-20T14:37:59.672550Z","shell.execute_reply":"2021-11-20T14:37:59.768632Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_idx = np.random.randint(len(input_chars))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:38:02.890000Z","iopub.execute_input":"2021-11-20T14:38:02.890560Z","iopub.status.idle":"2021-11-20T14:38:02.894049Z","shell.execute_reply.started":"2021-11-20T14:38:02.890524Z","shell.execute_reply":"2021-11-20T14:38:02.893344Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"input_chars[30]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:38:05.407649Z","iopub.execute_input":"2021-11-20T14:38:05.408169Z","iopub.status.idle":"2021-11-20T14:38:05.414196Z","shell.execute_reply.started":"2021-11-20T14:38:05.408130Z","shell.execute_reply":"2021-11-20T14:38:05.413300Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for iteration in range(NUM_ITERATIONS):\n    print(\"=\" * 50)\n    print(\"Iteration #: %d\" % (iteration))\n    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n    \n    # testing model\n    # randomly choose a row from input_chars, then use it to \n    # generate text from model for next 100 chars\n    test_idx = np.random.randint(len(input_chars))\n    test_chars = input_chars[30]\n    print(\"Generating from seed: %s\" % (test_chars))\n    print(test_chars, end=\"\")\n    for i in range(NUM_PREDS_PER_EPOCH):\n        Xtest = np.zeros((1, SEQLEN, nb_chars))\n        for i, ch in enumerate(test_chars):\n            Xtest[0, i, char2index[ch]] = 1\n        pred = model.predict(Xtest, verbose=0)[0]\n        ypred = index2char[np.argmax(pred)]\n        print(ypred, end=\"\")\n        # move forward with test_chars + ypred\n        test_chars = test_chars[1:] + ypred\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T14:38:14.874787Z","iopub.execute_input":"2021-11-20T14:38:14.875344Z","iopub.status.idle":"2021-11-20T14:59:45.700622Z","shell.execute_reply.started":"2021-11-20T14:38:14.875296Z","shell.execute_reply":"2021-11-20T14:59:45.699500Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}