{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\nfrom tensorflow.keras.models import Model\nfrom keras import backend as K\nfrom keras.utils.vis_utils import plot_model\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:01:43.715946Z","iopub.execute_input":"2021-11-24T14:01:43.716227Z","iopub.status.idle":"2021-11-24T14:01:48.677444Z","shell.execute_reply.started":"2021-11-24T14:01:43.716197Z","shell.execute_reply":"2021-11-24T14:01:48.676694Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = (128,128,3)\nBATCH_SIZE = 512\nZ_DIM = 128","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:01:23.862797Z","iopub.execute_input":"2021-11-24T14:01:23.863372Z","iopub.status.idle":"2021-11-24T14:01:23.868880Z","shell.execute_reply.started":"2021-11-24T14:01:23.863343Z","shell.execute_reply":"2021-11-24T14:01:23.868246Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_flow_test =ImageDataGenerator(rescale=1./255).flow_from_directory('../input/testcleb/testcleb', \n                                                                   target_size = INPUT_DIM[:2],\n                                                                   batch_size = 1500,\n                                                                   shuffle = True,\n                                                                   class_mode = 'input',\n                                                                   subset = 'training'\n                                                                   )","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:01:53.249923Z","iopub.execute_input":"2021-11-24T14:01:53.250529Z","iopub.status.idle":"2021-11-24T14:01:54.706557Z","shell.execute_reply.started":"2021-11-24T14:01:53.250484Z","shell.execute_reply":"2021-11-24T14:01:54.705789Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_flow=ImageDataGenerator(rescale=1./255).flow_from_directory('../input/cleberity1/traincleb/traincleb', \n                                                                   target_size = INPUT_DIM[:2],\n                                                                   batch_size = BATCH_SIZE,\n                                                                   shuffle = True,\n                                                                   class_mode = 'input',\n                                                                   subset = 'training'\n                                                                   )","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:03:21.557622Z","iopub.execute_input":"2021-11-24T14:03:21.557885Z","iopub.status.idle":"2021-11-24T14:03:42.421927Z","shell.execute_reply.started":"2021-11-24T14:03:21.557857Z","shell.execute_reply":"2021-11-24T14:03:42.421193Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import initializers\n\n\n# ENCODER\ndef build_vae_encoder(input_dim, output_dim, conv_filters, conv_kernel_size, \n                  conv_strides, use_batch_norm = False, use_dropout = False):\n  \n  global K\n  K.clear_session()\n  \n\n  n_layers = len(conv_filters)\n  encoder_input = Input(shape = input_dim, name = 'encoder_input',)\n  x = encoder_input\n\n  for i in range(n_layers):\n      x = Conv2D(filters = conv_filters[i], \n                  kernel_size = conv_kernel_size[i],\n                  strides = conv_strides[i], \n                  kernel_initializer=\"he_normal\",\n                  padding = 'same',\n                  name = 'encoder_conv_' + str(i)\n                  )(x)\n      if use_batch_norm:\n        x = BathcNormalization()(x)\n  \n      x = LeakyReLU()(x)\n\n      if use_dropout:\n        x = Dropout(rate=0.25)(x)\n        \n  shape_before_flattening = K.int_shape(x)[1:] \n  \n  x = Flatten()(x)\n  \n  mean_mu = Dense(output_dim, name = 'mu',kernel_initializer=\"he_normal\")(x)\n  log_var = Dense(output_dim, name = 'log_var',kernel_initializer=\"he_normal\")(x)\n\n  \n  def sampling(args):\n    mean_mu, log_var = args\n    epsilon = K.random_normal(shape=K.shape(mean_mu), mean=0., stddev=1.) \n    return mean_mu + K.exp(log_var/2)*epsilon   \n  \n  \n  encoder_output = Lambda(sampling, name='encoder_output')([mean_mu, log_var])\n\n  return encoder_input, encoder_output, mean_mu, log_var, shape_before_flattening, Model(encoder_input, encoder_output)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:12:58.341667Z","iopub.execute_input":"2021-11-24T14:12:58.341972Z","iopub.status.idle":"2021-11-24T14:12:58.359797Z","shell.execute_reply.started":"2021-11-24T14:12:58.341938Z","shell.execute_reply":"2021-11-24T14:12:58.358726Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"vae_encoder_input, vae_encoder_output,  mean_mu,log_var,  shape_before_flattening, vae_encoder  = build_vae_encoder(input_dim = INPUT_DIM,\n                                    output_dim = Z_DIM, \n                                    conv_filters = [32, 64, 64,64,64],\n                                    conv_kernel_size = [3,3,3,3,3],\n                                    conv_strides = [2,2,2,2,2])\n\nvae_encoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:01.773689Z","iopub.execute_input":"2021-11-24T14:13:01.773955Z","iopub.status.idle":"2021-11-24T14:13:01.889519Z","shell.execute_reply.started":"2021-11-24T14:13:01.773926Z","shell.execute_reply":"2021-11-24T14:13:01.888809Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Decoder\ndef build_decoder(input_dim, shape_before_flattening, conv_filters, conv_kernel_size, \n                  conv_strides):\n\n  \n  n_layers = len(conv_filters)\n  decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n\n  x = Dense(np.prod(shape_before_flattening))(decoder_input)\n  x = Reshape(shape_before_flattening)(x)\n\n\n  for i in range(n_layers):\n      x = Conv2DTranspose(filters = conv_filters[i], \n                  kernel_size = conv_kernel_size[i],\n                  kernel_initializer=\"he_normal\",\n                  strides = conv_strides[i], \n                  padding = 'same',\n                  name = 'decoder_conv_' + str(i)\n                  )(x)\n      \n      \n      if i < n_layers - 1:\n        x = LeakyReLU()(x)\n      else:\n        x = Activation('sigmoid')(x)\n  decoder_output = x\n\n  return decoder_input, decoder_output, Model(decoder_input, decoder_output)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:14.777769Z","iopub.execute_input":"2021-11-24T14:13:14.778050Z","iopub.status.idle":"2021-11-24T14:13:14.786627Z","shell.execute_reply.started":"2021-11-24T14:13:14.778009Z","shell.execute_reply":"2021-11-24T14:13:14.785461Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"decoder_input, decoder_output, vae_decoder = build_decoder(input_dim = Z_DIM,\n                                        shape_before_flattening = shape_before_flattening,\n                                        conv_filters = [64,64,64,32,3],\n                                        conv_kernel_size = [3,3,3,3,3],\n                                        conv_strides = [2,2,2,2,2]\n                                        )\nvae_decoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:17.267717Z","iopub.execute_input":"2021-11-24T14:13:17.267965Z","iopub.status.idle":"2021-11-24T14:13:17.390600Z","shell.execute_reply.started":"2021-11-24T14:13:17.267938Z","shell.execute_reply":"2021-11-24T14:13:17.389910Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.framework.ops import disable_eager_execution\ndisable_eager_execution()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:20.143086Z","iopub.execute_input":"2021-11-24T14:13:20.143640Z","iopub.status.idle":"2021-11-24T14:13:20.147816Z","shell.execute_reply.started":"2021-11-24T14:13:20.143601Z","shell.execute_reply":"2021-11-24T14:13:20.146826Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\nvae_input = vae_encoder_input\n\n\nvae_output = vae_decoder(vae_encoder_output)\n\n\nvae_model = Model(vae_input, vae_output)\n\nvae_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:22.061917Z","iopub.execute_input":"2021-11-24T14:13:22.062197Z","iopub.status.idle":"2021-11-24T14:13:22.126529Z","shell.execute_reply.started":"2021-11-24T14:13:22.062162Z","shell.execute_reply":"2021-11-24T14:13:22.125814Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 0.001\nN_EPOCHS = 10\nLOSS_FACTOR = 10000\n\ndef r_loss(y_true, y_pred):\n    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n\ndef kl_loss(y_true, y_pred):\n    kl_loss =  -0.5 * K.sum(1 + log_var - K.square(mean_mu) - K.exp(log_var), axis = 1)\n    return kl_loss\n\ndef total_loss(y_true, y_pred):\n    return LOSS_FACTOR*r_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\n  \ndef L1_loss(y_true,y_pre): \n    return K.sum(K.abs(y_true-y_pre))\n\ndef L2_loss(y_true,y_pre):\n    return K.sum(K.square(y_true-y_pre), axis = [1,2,3])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:26.563822Z","iopub.execute_input":"2021-11-24T14:13:26.564080Z","iopub.status.idle":"2021-11-24T14:13:26.572812Z","shell.execute_reply.started":"2021-11-24T14:13:26.564051Z","shell.execute_reply":"2021-11-24T14:13:26.571985Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import adam_v2\nadam_optimizer = adam_v2.Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\nvae_model.compile(optimizer=adam_optimizer, loss = L2_loss,metrics=[L2_loss]) # loss = L1_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:33.028979Z","iopub.execute_input":"2021-11-24T14:13:33.029237Z","iopub.status.idle":"2021-11-24T14:13:33.106862Z","shell.execute_reply.started":"2021-11-24T14:13:33.029208Z","shell.execute_reply":"2021-11-24T14:13:33.106192Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES= 17902\nvae_model.fit_generator(data_flow, \n                        shuffle=True, \n                        epochs = N_EPOCHS, \n                        initial_epoch = 0, \n                        steps_per_epoch=NUM_IMAGES / BATCH_SIZE\n                        )","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:13:35.243540Z","iopub.execute_input":"2021-11-24T14:13:35.244085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_batch = next(data_flow_test)\nexample_batch = example_batch[0]\nexample_images = example_batch[:10]\n\nimages = example_batch[:10]\nreconst_images = vae_model.predict(images)\nprint(example_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:04:56.589186Z","iopub.execute_input":"2021-11-20T05:04:56.589669Z","iopub.status.idle":"2021-11-20T05:05:01.715768Z","shell.execute_reply.started":"2021-11-20T05:04:56.58963Z","shell.execute_reply":"2021-11-20T05:05:01.715029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_compare_vae(images=None):\n  \n  if images is None:\n    example_batch = next(data_flow_test)\n    example_batch = example_batch[0]\n    images = example_batch[:10]\n\n  n_to_show = images.shape[0]\n  reconst_images = vae_model.predict(images)\n\n  fig = plt.figure(figsize=(15, 3))\n  fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n  for i in range(n_to_show):\n      img = images[i].squeeze()\n      sub = fig.add_subplot(2, n_to_show, i+1)\n      sub.axis('off')        \n      sub.imshow(img)\n\n  for i in range(n_to_show):\n      img = reconst_images[i].squeeze()\n      sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n      sub.axis('off')\n      sub.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:05:08.156169Z","iopub.execute_input":"2021-11-20T05:05:08.156828Z","iopub.status.idle":"2021-11-20T05:05:08.167828Z","shell.execute_reply.started":"2021-11-20T05:05:08.156774Z","shell.execute_reply":"2021-11-20T05:05:08.167043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplot_compare_vae(images = example_images)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:05:12.199185Z","iopub.execute_input":"2021-11-20T05:05:12.199915Z","iopub.status.idle":"2021-11-20T05:05:13.059833Z","shell.execute_reply.started":"2021-11-20T05:05:12.199877Z","shell.execute_reply":"2021-11-20T05:05:13.059119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vae_generate_images(n_to_show=10):\n  reconst_images = vae_decoder.predict(np.random.normal(0,1,size=(n_to_show,Z_DIM)))\n\n  fig = plt.figure(figsize=(15, 3))\n  fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n  for i in range(n_to_show):\n        img = reconst_images[i].squeeze()\n        sub = fig.add_subplot(2, n_to_show, i+1)\n        sub.axis('off')        \n        sub.imshow(img)\n        \nvae_generate_images(n_to_show=10)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:05:28.3656Z","iopub.execute_input":"2021-11-20T05:05:28.366415Z","iopub.status.idle":"2021-11-20T05:05:29.229888Z","shell.execute_reply.started":"2021-11-20T05:05:28.366365Z","shell.execute_reply":"2021-11-20T05:05:29.229134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile utils.py\nimport numpy as np\nfrom numpy import cov\nfrom numpy import trace\nfrom numpy import iscomplexobj\nfrom numpy import asarray\nfrom numpy.random import randint\nfrom scipy.linalg import sqrtm\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.datasets.mnist import load_data\nfrom tensorflow.keras.models import load_model\nfrom skimage.transform import resize\nimport math\n\ndef scale_images(images, new_shape):\n\timages_list = list()\n\tfor image in images:\n\t\t# resize with nearest neighbor interpolation\n\t\tnew_image = resize(image, new_shape, 0)\n\t\t# store\n\t\timages_list.append(new_image)\n\treturn asarray(images_list)\n \n# calculate frechet inception distance\ndef calculate_fid(model, images1, images2):\n\t# calculate activations\n\tact1 = model.predict(images1)\n\tact2 = model.predict(images2)\n\t# calculate mean and covariance statistics\n\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n\t# calculate sum squared difference between means\n\tssdiff = np.sum((mu1 - mu2)**2.0)\n\t# calculate sqrt of product between cov\n\tcovmean = sqrtm(sigma1.dot(sigma2))\n\t# check and correct imaginary numbers from sqrt\n\tif iscomplexobj(covmean):\n\t\tcovmean = covmean.real\n\t# calculate score\n\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n\treturn fid\n \n# prepare the inception v3 model\n\ndef getFID(real_images, fake_images):\n\t'''\n\treal_images : your real images B,W,H,C\n\tfake_images : your fake images B,W,H,C\n\t\n\n\t'''\n\t\n\tmodel = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n\n\tassert real_images.shape == fake_images.shape, ' Images should have identical shape !!'\n\t\n\tprint('YOUR input size is ', real_images.shape, fake_images.shape)\n\t# convert integer to floating point values\n\timages1 = real_images.astype('float32')\n\timages2 = fake_images.astype('float32')\n\t# resize images\n\timages1 = scale_images(images1, (299,299,3))\n\timages2 = scale_images(images2, (299,299,3))\n\tprint('Scaled', images1.shape, images2.shape)\n\t# pre-process images\n\timages1 = preprocess_input(images1)\n\timages2 = preprocess_input(images2)\n\n\t# fid between images1 and images2\n\tfid = calculate_fid(model, images1, images2) * 10\n\tprint('FID of your Fake Output: %.3f' % fid)\n\nif __name__ == '__main__':\n\timages1 = randint(0, 255, 10*32*32*3)\n\timages1 = images1.reshape((10,32,32,3))\n\timages2 = randint(0, 255, 10*32*32*3)\n\timages2 = images2.reshape((10,32,32,3))\n\tgetFID(images1,images2)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:06:41.897179Z","iopub.execute_input":"2021-11-20T05:06:41.897727Z","iopub.status.idle":"2021-11-20T05:06:41.9075Z","shell.execute_reply.started":"2021-11-20T05:06:41.897689Z","shell.execute_reply":"2021-11-20T05:06:41.904789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytorch","metadata":{"execution":{"iopub.status.busy":"2021-11-23T14:19:14.463387Z","iopub.execute_input":"2021-11-23T14:19:14.463752Z","iopub.status.idle":"2021-11-23T14:19:14.541407Z","shell.execute_reply.started":"2021-11-23T14:19:14.463652Z","shell.execute_reply":"2021-11-23T14:19:14.540103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import getFID","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:06:45.60742Z","iopub.execute_input":"2021-11-20T05:06:45.60795Z","iopub.status.idle":"2021-11-20T05:06:46.425022Z","shell.execute_reply.started":"2021-11-20T05:06:45.60791Z","shell.execute_reply":"2021-11-20T05:06:46.424241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getFID(images, reconst_images)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:07:02.656262Z","iopub.execute_input":"2021-11-20T05:07:02.656815Z","iopub.status.idle":"2021-11-20T05:07:21.603703Z","shell.execute_reply.started":"2021-11-20T05:07:02.656774Z","shell.execute_reply":"2021-11-20T05:07:21.602932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_image= vae_decoder.predict(np.random.normal(0,1,size=(1500,Z_DIM)))\ngetFID(example_batch, generated_image)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:07:42.929359Z","iopub.execute_input":"2021-11-20T05:07:42.930122Z","iopub.status.idle":"2021-11-20T05:08:35.720291Z","shell.execute_reply.started":"2021-11-20T05:07:42.930078Z","shell.execute_reply":"2021-11-20T05:08:35.719528Z"},"trusted":true},"execution_count":null,"outputs":[]}]}